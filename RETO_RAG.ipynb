{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Sistema RAG (Retrieval-Augmented Generation) Optimizado\n",
    "\n",
    "**Certificado en Desarrollo de Software con IA Generativa**  \n",
    "**M1. Introducci√≥n a la IA en el Desarrollo de Software**\n",
    "\n",
    "Este notebook implementa un sistema completo de RAG optimizado que combina:\n",
    "- Carga autom√°tica de documentos desde directorio sample_docs/\n",
    "- Extracci√≥n y procesamiento de documentos PDF y TXT\n",
    "- Chunking optimizado (1200 caracteres con overlap 200)\\n- Creaci√≥n de embeddings vectoriales\n",
    "- Almacenamiento en base de datos vectorial persistente\n",
    "- Recuperaci√≥n MMR (Maximal Marginal Relevance) para mayor diversidad\n",
    "- Generaci√≥n de respuestas contextualizadas\n",
    "- Validaci√≥n con preguntas cr√≠ticas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_header",
   "metadata": {},
   "source": [
    "## 0. Setup y Configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "install_deps",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T06:29:53.505008Z",
     "start_time": "2025-09-17T06:29:52.382914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Instalar dependencias (ejecutar solo la primera vez)\n",
    "!pip install -qU openai langchain langchain-openai langchain-chroma langchain-community chromadb pypdf python-dotenv tqdm --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "imports",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T06:29:53.516695Z",
     "start_time": "2025-09-17T06:29:53.512695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Todas las librer√≠as importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "# Importar librer√≠as necesarias\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "import json\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Cargar variables de entorno\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Importar componentes de LangChain y OpenAI\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "# IMPORTANTE: usar langchain_community en lugar de langchain.document_loaders (deprecado)\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "import chromadb\n",
    "\n",
    "print(\"‚úÖ Todas las librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "config",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T06:29:53.530215Z",
     "start_time": "2025-09-17T06:29:53.528018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API Key configurada\n",
      "üìã Configuraci√≥n optimizada: {'chunk_size': 800, 'chunk_overlap': 200, 'embedding_model': 'text-embedding-3-small', 'llm_model': 'gpt-4o-mini', 'persist_directory': './chroma_db', 'retrieval_k': 5, 'search_type': 'mmr'}\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n del sistema\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"‚ùå No se encontr√≥ OPENAI_API_KEY\")\n",
    "    print(\"Por favor configura tu API key en el archivo .env\")\n",
    "else:\n",
    "    print(\"‚úÖ API Key configurada\")\n",
    "\n",
    "# Configuraciones optimizadas del sistema\n",
    "CONFIG = {\n",
    "    \"chunk_size\": 1200,       # Optimizado para mejor contexto\\n    \"chunk_overlap\": 200,     # Mantenido para continuidad\n",
    "    \"embedding_model\": \"text-embedding-3-small\",\n",
    "    \"llm_model\": \"gpt-4o-mini\",\n",
    "    \"persist_directory\": \"./chroma_db\",\n",
    "    \"retrieval_k\": 7,         # Aumentado para mayor cobertura\\n    \"search_type\": \"mmr\"      # MMR para diversidad sem√°ntica\n",
    "}\n",
    "\n",
    "print(f\"üìã Configuraci√≥n optimizada: {CONFIG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraction_header",
   "metadata": {},
   "source": [
    "## 1. Extracci√≥n de Archivos con Carga Autom√°tica\n",
    "\n",
    "En esta secci√≥n extraemos texto de documentos PDF y TXT usando carga autom√°tica desde el directorio sample_docs/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "create_sample_docs",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T06:29:53.547946Z",
     "start_time": "2025-09-17T06:29:53.544541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Documentos de ejemplo creados: ['sample_docs/manual_politicas.txt', 'sample_docs/guia_desarrollo.txt']\n"
     ]
    }
   ],
   "source": [
    "# Crear documentos de ejemplo para la demostraci√≥n\n",
    "def create_sample_documents():\n",
    "    \"\"\"Crea documentos de ejemplo si no existen archivos\"\"\"\n",
    "    sample_dir = Path(\"sample_docs\")\n",
    "    sample_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Documento 1: Manual de pol√≠ticas de empresa\n",
    "    doc1_content = \"\"\"\n",
    "Manual de Pol√≠ticas de la Empresa TechCorp\n",
    "\n",
    "1. POL√çTICAS DE TRABAJO REMOTO\n",
    "\n",
    "1.1 Elegibilidad\n",
    "Los empleados pueden trabajar de forma remota si:\n",
    "- Han completado al menos 6 meses en la empresa\n",
    "- Su supervisor directo aprueba la solicitud\n",
    "- Su rol permite trabajo remoto efectivo\n",
    "\n",
    "1.2 Horarios de Trabajo\n",
    "- Horario flexible entre 7:00 AM y 7:00 PM\n",
    "- M√≠nimo 6 horas de solapamiento con el equipo\n",
    "- Disponibilidad para reuniones importantes\n",
    "\n",
    "2. POL√çTICAS DE VACACIONES\n",
    "\n",
    "2.1 D√≠as de Vacaciones\n",
    "- Empleados nuevos: 15 d√≠as al a√±o\n",
    "- Empleados con 2+ a√±os: 20 d√≠as al a√±o\n",
    "- Empleados con 5+ a√±os: 25 d√≠as al a√±o\n",
    "\n",
    "2.2 Solicitud de Vacaciones\n",
    "- Solicitar con al menos 2 semanas de anticipaci√≥n\n",
    "- Aprobaci√≥n requerida del supervisor\n",
    "- No m√°s de 10 d√≠as consecutivos sin aprobaci√≥n especial\n",
    "\n",
    "3. C√ìDIGO DE CONDUCTA\n",
    "\n",
    "3.1 Principios B√°sicos\n",
    "- Respeto mutuo entre colegas\n",
    "- Confidencialidad de informaci√≥n empresarial\n",
    "- Profesionalismo en todas las interacciones\n",
    "\n",
    "3.2 Uso de Tecnolog√≠a\n",
    "- Equipos de la empresa solo para uso profesional\n",
    "- Prohibido instalar software no autorizado\n",
    "- Reportar inmediatamente cualquier problema de seguridad\n",
    "    \"\"\"\n",
    "    \n",
    "    # Documento 2: Gu√≠a t√©cnica de desarrollo\n",
    "    doc2_content = \"\"\"\n",
    "Gu√≠a de Desarrollo de Software - TechCorp\n",
    "\n",
    "1. EST√ÅNDARES DE C√ìDIGO\n",
    "\n",
    "1.1 Lenguajes de Programaci√≥n\n",
    "- Python: Seguir PEP 8\n",
    "- JavaScript: Usar ESLint con configuraci√≥n est√°ndar\n",
    "- Java: Seguir Google Java Style Guide\n",
    "\n",
    "1.2 Documentaci√≥n\n",
    "- Todos los m√©todos p√∫blicos deben tener docstrings\n",
    "- README.md obligatorio en cada repositorio\n",
    "- Comentarios en c√≥digo complejo\n",
    "\n",
    "2. CONTROL DE VERSIONES\n",
    "\n",
    "2.1 Git Workflow\n",
    "- Usar GitFlow para manejo de ramas\n",
    "- Commits descriptivos y at√≥micos\n",
    "- Pull requests obligatorios para main\n",
    "\n",
    "2.2 Revisi√≥n de C√≥digo\n",
    "- Al menos 2 revisores para cambios cr√≠ticos\n",
    "- Ejecutar tests antes de merge\n",
    "- Revisar seguridad y performance\n",
    "\n",
    "3. TESTING\n",
    "\n",
    "3.1 Cobertura de Tests\n",
    "- M√≠nimo 80% de cobertura de c√≥digo\n",
    "- Tests unitarios para toda l√≥gica de negocio\n",
    "- Tests de integraci√≥n para APIs\n",
    "\n",
    "3.2 Automatizaci√≥n\n",
    "- CI/CD pipeline configurado\n",
    "- Tests autom√°ticos en cada PR\n",
    "- Deploy autom√°tico a staging\n",
    "\n",
    "4. SEGURIDAD\n",
    "\n",
    "4.1 Mejores Pr√°cticas\n",
    "- Nunca hardcodear credenciales\n",
    "- Usar variables de entorno para configuraci√≥n\n",
    "- Validar todas las entradas de usuario\n",
    "\n",
    "4.2 Dependencias\n",
    "- Mantener dependencias actualizadas\n",
    "- Escaneo de vulnerabilidades semanal\n",
    "- Usar herramientas como Snyk o OWASP\n",
    "\n",
    "5. DEPLOYMENT\n",
    "\n",
    "5.1 Ambientes\n",
    "- Development: Para desarrollo local\n",
    "- Staging: Para testing de QA\n",
    "- Production: Ambiente productivo\n",
    "\n",
    "5.2 Proceso de Deploy\n",
    "- Deploy solo desde rama main\n",
    "- Backup antes de cada deploy a producci√≥n\n",
    "- Rollback plan siempre disponible\n",
    "    \"\"\"\n",
    "    \n",
    "    # Guardar documentos\n",
    "    with open(sample_dir / \"manual_politicas.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(doc1_content)\n",
    "        \n",
    "    with open(sample_dir / \"guia_desarrollo.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(doc2_content)\n",
    "    \n",
    "    return [str(sample_dir / \"manual_politicas.txt\"), str(sample_dir / \"guia_desarrollo.txt\")]\n",
    "\n",
    "# Crear documentos de ejemplo\n",
    "sample_files = create_sample_documents()\n",
    "print(f\"üìÅ Documentos de ejemplo creados: {sample_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "load_documents",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T06:29:53.564805Z",
     "start_time": "2025-09-17T06:29:53.557610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Encontrados 5 archivos en sample_docs:\n",
      "   - reporte_ventas_2025_Q1_Q2.txt\n",
      "   - informe_proyectos_estrategicos_2025.txt\n",
      "   - guia_desarrollo.txt\n",
      "   - reporte_ventas_2024.txt\n",
      "   - manual_politicas.txt\n",
      "‚úÖ Cargado TXT: reporte_ventas_2025_Q1_Q2.txt\n",
      "‚úÖ Cargado TXT: informe_proyectos_estrategicos_2025.txt\n",
      "‚úÖ Cargado TXT: guia_desarrollo.txt\n",
      "‚úÖ Cargado TXT: reporte_ventas_2024.txt\n",
      "‚úÖ Cargado TXT: manual_politicas.txt\n",
      "\n",
      "üìÑ Total de documentos cargados: 5\n",
      "Documento 1:\n",
      "  - Archivo: reporte_ventas_2025_Q1_Q2.txt\n",
      "  - Tipo: txt\n",
      "  - Longitud: 5361 caracteres\n",
      "  - Preview: REPORTE DE VENTAS 2025 (Q1‚ÄìQ2) ‚Äì TECHCORP  \n",
      "Departamento Comercial  \n",
      "Fecha de publicaci√≥n: 15 de jul...\n",
      "\n",
      "Documento 2:\n",
      "  - Archivo: informe_proyectos_estrategicos_2025.txt\n",
      "  - Tipo: txt\n",
      "  - Longitud: 6329 caracteres\n",
      "  - Preview: INFORME DE SEGUIMIENTO DE PROYECTOS ESTRAT√âGICOS 2025 ‚Äì TECHCORP  \n",
      "Oficina de Planeaci√≥n y Ejecuci√≥n...\n",
      "\n",
      "Documento 3:\n",
      "  - Archivo: guia_desarrollo.txt\n",
      "  - Tipo: txt\n",
      "  - Longitud: 1463 caracteres\n",
      "  - Preview: \n",
      "Gu√≠a de Desarrollo de Software - TechCorp\n",
      "\n",
      "1. EST√ÅNDARES DE C√ìDIGO\n",
      "\n",
      "1.1 Lenguajes de Programaci√≥n\n",
      "-...\n",
      "\n",
      "Documento 4:\n",
      "  - Archivo: reporte_ventas_2024.txt\n",
      "  - Tipo: txt\n",
      "  - Longitud: 4252 caracteres\n",
      "  - Preview: REPORTE ANUAL DE VENTAS 2024 ‚Äì TECHCORP  \n",
      "Departamento Comercial  \n",
      "Fecha de publicaci√≥n: 15 de enero...\n",
      "\n",
      "Documento 5:\n",
      "  - Archivo: manual_politicas.txt\n",
      "  - Tipo: txt\n",
      "  - Longitud: 1126 caracteres\n",
      "  - Preview: \n",
      "Manual de Pol√≠ticas de la Empresa TechCorp\n",
      "\n",
      "1. POL√çTICAS DE TRABAJO REMOTO\n",
      "\n",
      "1.1 Elegibilidad\n",
      "Los em...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Funci√≥n para cargar documentos autom√°ticamente desde directorio\n",
    "def load_documents_from_directory(directory_path: str) -> List[Document]:\n",
    "    \"\"\"Carga autom√°ticamente todos los archivos PDF y TXT desde un directorio\"\"\"\n",
    "    documents = []\n",
    "    directory = Path(directory_path)\n",
    "    \n",
    "    if not directory.exists():\n",
    "        print(f\"‚ùå Directorio no existe: {directory_path}\")\n",
    "        return documents\n",
    "    \n",
    "    # Buscar archivos PDF y TXT\n",
    "    pdf_files = list(directory.glob(\"*.pdf\"))\n",
    "    txt_files = list(directory.glob(\"*.txt\"))\n",
    "    \n",
    "    all_files = pdf_files + txt_files\n",
    "    \n",
    "    print(f\"üìÅ Encontrados {len(all_files)} archivos en {directory_path}:\")\n",
    "    for file in all_files:\n",
    "        print(f\"   - {file.name}\")\n",
    "    \n",
    "    for file_path in all_files:\n",
    "        try:\n",
    "            if file_path.suffix.lower() == '.pdf':\n",
    "                # IMPORTANTE: usar langchain_community en lugar de langchain.document_loaders\n",
    "                loader = PyPDFLoader(str(file_path))\n",
    "                docs = loader.load()\n",
    "                print(f\"‚úÖ Cargado PDF: {file_path.name} ({len(docs)} p√°ginas)\")\n",
    "                \n",
    "            elif file_path.suffix.lower() == '.txt':\n",
    "                loader = TextLoader(str(file_path), encoding='utf-8')\n",
    "                docs = loader.load()\n",
    "                print(f\"‚úÖ Cargado TXT: {file_path.name}\")\n",
    "                \n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "            # Agregar metadatos enriquecidos\n",
    "            for doc in docs:\n",
    "                doc.metadata['source_file'] = file_path.name\n",
    "                doc.metadata['file_type'] = file_path.suffix[1:]  # sin el punto\n",
    "                doc.metadata['file_path'] = str(file_path)\n",
    "            \n",
    "            documents.extend(docs)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error cargando {file_path.name}: {e}\")\n",
    "            \n",
    "    return documents\n",
    "\n",
    "# Cargar documentos autom√°ticamente\n",
    "documents = load_documents_from_directory(\"sample_docs\")\n",
    "print(f\"\\nüìÑ Total de documentos cargados: {len(documents)}\")\n",
    "\n",
    "# Mostrar informaci√≥n detallada de los documentos\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"Documento {i+1}:\")\n",
    "    print(f\"  - Archivo: {doc.metadata['source_file']}\")\n",
    "    print(f\"  - Tipo: {doc.metadata['file_type']}\")\n",
    "    print(f\"  - Longitud: {len(doc.page_content)} caracteres\")\n",
    "    print(f\"  - Preview: {doc.page_content[:100]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chunking_header",
   "metadata": {},
   "source": [
    "## 2. Divisi√≥n de Texto en Fragmentos Optimizada (Chunking)\n",
    "\n",
    "Dividimos los documentos en fragmentos optimizados de 1200 caracteres para mejor continuidad contextual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "text_splitting",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T06:29:53.573488Z",
     "start_time": "2025-09-17T06:29:53.569565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Configurado divisor de texto optimizado:\n",
      "  - Tama√±o de fragmento: 800 caracteres (optimizado)\n",
      "  - Solapamiento: 200 caracteres\n",
      "  - Mejora: chunks m√°s peque√±os para mejor continuidad contextual\n",
      "\n",
      "‚úÇÔ∏è Documentos divididos en 32 fragmentos optimizados\n",
      "\n",
      "üìã Informaci√≥n de fragmentos optimizados:\n",
      "Fragmento 1:\n",
      "  - Archivo origen: reporte_ventas_2025_Q1_Q2.txt\n",
      "  - ID: 0\n",
      "  - Tama√±o: 614 caracteres\n",
      "  - Contenido: REPORTE DE VENTAS 2025 (Q1‚ÄìQ2) ‚Äì TECHCORP  \n",
      "Departamento Comercial  \n",
      "Fecha de publicaci√≥n: 15 de julio de 2025\n",
      "\n",
      "1. RESUMEN EJECUTIVO\n",
      "\n",
      "Durante el prime...\n",
      "\n",
      "Fragmento 2:\n",
      "  - Archivo origen: reporte_ventas_2025_Q1_Q2.txt\n",
      "  - ID: 1\n",
      "  - Tama√±o: 584 caracteres\n",
      "  - Contenido: 2. DETALLE DE VENTAS POR TRIMESTRE\n",
      "\n",
      "Q1 2025 (Enero - Marzo)  \n",
      "Ingresos totales: $129,400,000 MXN  \n",
      "Producto l√≠der: TechSuite CRM Cloud 2.0 (42% de las...\n",
      "\n",
      "Fragmento 3:\n",
      "  - Archivo origen: reporte_ventas_2025_Q1_Q2.txt\n",
      "  - ID: 2\n",
      "  - Tama√±o: 733 caracteres\n",
      "  - Contenido: Q2 2025 (Abril - Junio)  \n",
      "Ingresos totales: $138,500,000 MXN  \n",
      "Producto l√≠der: SmartFleet 360 (35% de las ventas)  \n",
      "Regi√≥n con mayor crecimiento: Nort...\n",
      "\n",
      "üìä Estad√≠sticas de fragmentos:\n",
      "  - Tama√±o promedio: 656.2 caracteres\n",
      "  - Tama√±o m√≠nimo: 260 caracteres\n",
      "  - Tama√±o m√°ximo: 798 caracteres\n"
     ]
    }
   ],
   "source": [
    "# Configurar el divisor de texto optimizado\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CONFIG[\"chunk_size\"],\n",
    "    chunk_overlap=CONFIG[\"chunk_overlap\"],\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "print(f\"üîß Configurado divisor de texto optimizado:\")\n",
    "print(f\"  - Tama√±o de fragmento: {CONFIG['chunk_size']} caracteres (optimizado)\")\n",
    "print(f\"  - Solapamiento: {CONFIG['chunk_overlap']} caracteres\")\n",
    "print(f\"  - Mejora: chunks m√°s peque√±os para mejor continuidad contextual\")\n",
    "\n",
    "# Dividir documentos en fragmentos\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# Agregar metadatos de fragmento\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk.metadata['chunk_id'] = i\n",
    "    chunk.metadata['chunk_size'] = len(chunk.page_content)\n",
    "\n",
    "print(f\"\\n‚úÇÔ∏è Documentos divididos en {len(chunks)} fragmentos optimizados\")\n",
    "\n",
    "# Mostrar informaci√≥n de algunos fragmentos\n",
    "print(\"\\nüìã Informaci√≥n de fragmentos optimizados:\")\n",
    "for i, chunk in enumerate(chunks[:3]):  # Mostrar primeros 3 fragmentos\n",
    "    print(f\"Fragmento {i+1}:\")\n",
    "    print(f\"  - Archivo origen: {chunk.metadata['source_file']}\")\n",
    "    print(f\"  - ID: {chunk.metadata['chunk_id']}\")\n",
    "    print(f\"  - Tama√±o: {chunk.metadata['chunk_size']} caracteres\")\n",
    "    print(f\"  - Contenido: {chunk.page_content[:150]}...\\n\")\n",
    "\n",
    "# An√°lisis de distribuci√≥n de tama√±os\n",
    "chunk_sizes = [chunk.metadata['chunk_size'] for chunk in chunks]\n",
    "print(f\"üìä Estad√≠sticas de fragmentos:\")\n",
    "print(f\"  - Tama√±o promedio: {sum(chunk_sizes)/len(chunk_sizes):.1f} caracteres\")\n",
    "print(f\"  - Tama√±o m√≠nimo: {min(chunk_sizes)} caracteres\") \n",
    "print(f\"  - Tama√±o m√°ximo: {max(chunk_sizes)} caracteres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedding_header",
   "metadata": {},
   "source": [
    "## 3. Creaci√≥n de Embeddings\n",
    "\n",
    "Convertimos el texto en representaciones vectoriales usando OpenAI embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "setup_embeddings",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T06:29:54.055957Z",
     "start_time": "2025-09-17T06:29:53.578789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Configurado modelo de embeddings: text-embedding-3-small\n",
      "\n",
      "üß™ Probando generaci√≥n de embeddings...\n",
      "‚úÖ Embeddings generados exitosamente\n",
      "  - N√∫mero de vectores: 2\n",
      "  - Dimensiones por vector: 1536\n",
      "  - Primeros 5 valores del vector 1: [0.006555972620844841, 0.0550614595413208, 0.029425645247101784, 0.03929227590560913, 0.0010066740214824677]\n"
     ]
    }
   ],
   "source": [
    "# Configurar embeddings de OpenAI\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=CONFIG[\"embedding_model\"],\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "print(f\"üß† Configurado modelo de embeddings: {CONFIG['embedding_model']}\")\n",
    "\n",
    "# Probar embeddings con texto de ejemplo\n",
    "sample_texts = [\n",
    "    \"Los empleados nuevos tienen 15 d√≠as de vacaciones al a√±o\",\n",
    "    \"El c√≥digo Python debe seguir el est√°ndar PEP 8\"\n",
    "]\n",
    "\n",
    "print(\"\\nüß™ Probando generaci√≥n de embeddings...\")\n",
    "try:\n",
    "    sample_vectors = embeddings.embed_documents(sample_texts)\n",
    "    print(f\"‚úÖ Embeddings generados exitosamente\")\n",
    "    print(f\"  - N√∫mero de vectores: {len(sample_vectors)}\")\n",
    "    print(f\"  - Dimensiones por vector: {len(sample_vectors[0])}\")\n",
    "    print(f\"  - Primeros 5 valores del vector 1: {sample_vectors[0][:5]}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error generando embeddings: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vectorstore_header",
   "metadata": {},
   "source": [
    "## 4. Base de Datos Vectorial (Vector Store)\n",
    "\n",
    "Almacenamos los embeddings en ChromaDB para b√∫squeda eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "setup_vectorstore",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T06:29:54.076038Z",
     "start_time": "2025-09-17T06:29:54.068875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóÑÔ∏è Configurando base de datos vectorial:\n",
      "  - Directorio: ./chroma_db\n",
      "  - Colecci√≥n: rag_documents\n",
      "‚úÖ ChromaDB inicializado\n",
      "üìä Documentos existentes en la base de datos: 201\n"
     ]
    }
   ],
   "source": [
    "# Configurar ChromaDB\n",
    "persist_directory = CONFIG[\"persist_directory\"]\n",
    "\n",
    "print(f\"üóÑÔ∏è Configurando base de datos vectorial:\")\n",
    "print(f\"  - Directorio: {persist_directory}\")\n",
    "print(f\"  - Colecci√≥n: rag_documents\")\n",
    "\n",
    "# Crear vectorstore\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"rag_documents\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "print(\"‚úÖ ChromaDB inicializado\")\n",
    "\n",
    "# Verificar si ya hay documentos en la base de datos\n",
    "try:\n",
    "    collection_count = vectorstore._collection.count()\n",
    "    print(f\"üìä Documentos existentes en la base de datos: {collection_count}\")\n",
    "except:\n",
    "    print(\"üìä Base de datos nueva (sin documentos previos)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "index_documents",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T06:29:55.776997Z",
     "start_time": "2025-09-17T06:29:54.086858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Indexando documentos en ChromaDB...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9eb953b8784ca8a7fc50426ded74c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Indexando fragmentos:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "jetTransient": {
      "display_id": null
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Indexaci√≥n completada\n",
      "üìä Total de documentos en la base de datos: 233\n",
      "üìÑ Fragmentos procesados: 32\n"
     ]
    }
   ],
   "source": [
    "# Indexar documentos en la base de datos vectorial\n",
    "print(\"üîÑ Indexando documentos en ChromaDB...\")\n",
    "\n",
    "batch_size = 50  # Procesar en lotes para evitar rate limits\n",
    "\n",
    "for i in tqdm(range(0, len(chunks), batch_size), desc=\"Indexando fragmentos\"):\n",
    "    batch = chunks[i:i + batch_size]\n",
    "    \n",
    "    try:\n",
    "        vectorstore.add_documents(batch)\n",
    "        time.sleep(1)  # Pausa para evitar rate limits\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en lote {i//batch_size + 1}: {e}\")\n",
    "        time.sleep(5)  # Pausa m√°s larga en caso de error\n",
    "        \n",
    "        # Reintentar el lote\n",
    "        try:\n",
    "            vectorstore.add_documents(batch)\n",
    "        except Exception as e2:\n",
    "            print(f\"‚ùå Fallo definitivo en lote {i//batch_size + 1}: {e2}\")\n",
    "\n",
    "# Verificar indexaci√≥n\n",
    "final_count = vectorstore._collection.count()\n",
    "print(f\"\\n‚úÖ Indexaci√≥n completada\")\n",
    "print(f\"üìä Total de documentos en la base de datos: {final_count}\")\n",
    "print(f\"üìÑ Fragmentos procesados: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retrieval_header",
   "metadata": {},
   "source": [
    "## 5. Recuperaci√≥n con MMR (Maximal Marginal Relevance)\n",
    "\n",
    "Configuramos el sistema de recuperaci√≥n optimizado con MMR para mayor diversidad sem√°ntica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "setup_retrieval",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T06:29:56.451634Z",
     "start_time": "2025-09-17T06:29:55.814255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Recuperador optimizado configurado:\n",
      "  - Tipo de b√∫squeda: mmr (Maximal Marginal Relevance)\n",
      "  - Documentos a recuperar: 5\n",
      "  - Candidatos para MMR: 20\n",
      "  - Lambda mult: 0.7 (balance diversidad/relevancia)\n",
      "\n",
      "üß™ Comparando tipos de b√∫squeda con: '¬øCu√°ntos d√≠as de vacaciones tienen los empleados?'\n",
      "\n",
      "üìã B√∫squeda por SIMILARIDAD (tradicional):\n",
      "  1. Score: 0.547 | - Empleados con 2+ a√±os: 20 d√≠as al a√±o\n",
      "    - Empleados con 5+ a√±os: 25 d√≠as al a√±o\n",
      "    \n",
      "    2.2 Sol...\n",
      "  2. Score: 0.789 | 2.2 Solicitud de Vacaciones\n",
      "- Solicitar con al menos 2 semanas de anticipaci√≥n\n",
      "- Aprobaci√≥n requerid...\n",
      "  3. Score: 0.789 | 2.2 Solicitud de Vacaciones\n",
      "- Solicitar con al menos 2 semanas de anticipaci√≥n\n",
      "- Aprobaci√≥n requerid...\n",
      "\n",
      "üéØ B√∫squeda con MMR (diversidad optimizada):\n",
      "  1. Fuente: manual_politicas.txt | - Empleados con 2+ a√±os: 20 d√≠as al a√±o\n",
      "    - Empleados con 5+ a√±os: 25 d√≠as al a√±o\n",
      "    \n",
      "    2.2 Sol...\n",
      "  2. Fuente: manual_politicas.txt | 2.2 Solicitud de Vacaciones\n",
      "- Solicitar con al menos 2 semanas de anticipaci√≥n\n",
      "- Aprobaci√≥n requerid...\n",
      "  3. Fuente: manual_politicas.txt | 2.2 Solicitud de Vacaciones\n",
      "- Solicitar con al menos 2 semanas de anticipaci√≥n\n",
      "- Aprobaci√≥n requerid...\n",
      "\n",
      "üí° MMR proporciona mayor diversidad sem√°ntica en los resultados\n"
     ]
    }
   ],
   "source": [
    "# Configurar el recuperador con MMR\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=CONFIG[\"search_type\"],  # \"mmr\" para mayor diversidad\n",
    "    search_kwargs={\n",
    "        \"k\": CONFIG[\"retrieval_k\"],\n",
    "        \"fetch_k\": 20,  # Documentos candidatos para MMR\n",
    "        \"lambda_mult\": 0.5  # Balance diversidad vs relevancia\\n    }\n",
    ")\n",
    "\n",
    "print(f\"üîç Recuperador optimizado configurado:\")\n",
    "print(f\"  - Tipo de b√∫squeda: {CONFIG['search_type']} (Maximal Marginal Relevance)\")\n",
    "print(f\"  - Documentos a recuperar: {CONFIG['retrieval_k']}\")\n",
    "print(f\"  - Candidatos para MMR: 20\")\n",
    "print(f\"  - Lambda mult: 0.7 (balance diversidad/relevancia)\")\n",
    "\n",
    "# Comparar b√∫squeda similarity vs MMR\n",
    "test_query = \"¬øCu√°ntos d√≠as de vacaciones tienen los empleados?\"\n",
    "print(f\"\\nüß™ Comparando tipos de b√∫squeda con: '{test_query}'\")\n",
    "\n",
    "try:\n",
    "    # B√∫squeda por similaridad tradicional\n",
    "    docs_similarity = vectorstore.similarity_search_with_score(test_query, k=3)\n",
    "    print(f\"\\nüìã B√∫squeda por SIMILARIDAD (tradicional):\")\n",
    "    for i, (doc, score) in enumerate(docs_similarity, 1):\n",
    "        print(f\"  {i}. Score: {score:.3f} | {doc.page_content[:100]}...\")\n",
    "    \n",
    "    # B√∫squeda con MMR\n",
    "    docs_mmr = retriever.invoke(test_query)\n",
    "    print(f\"\\nüéØ B√∫squeda con MMR (diversidad optimizada):\")\n",
    "    for i, doc in enumerate(docs_mmr[:3], 1):\n",
    "        print(f\"  {i}. Fuente: {doc.metadata['source_file']} | {doc.page_content[:100]}...\")\n",
    "        \n",
    "    print(f\"\\nüí° MMR proporciona mayor diversidad sem√°ntica en los resultados\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error en b√∫squeda: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "langchain_retriever_header",
   "metadata": {},
   "source": [
    "## 6. Sistema RAG Completo con LangChain\n",
    "\n",
    "Configuramos el sistema completo de pregunta-respuesta usando LangChain con optimizaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "setup_llm",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T06:29:56.845945Z",
     "start_time": "2025-09-17T06:29:56.461482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Modelo de lenguaje configurado: gpt-4o-mini\n",
      "  - Temperatura: 0 (respuestas determin√≠sticas)\n",
      "  - Tokens m√°ximos: 2000\n",
      "\n",
      "üß™ Prueba del LLM:\n",
      "  - Pregunta: ¬øCu√°l es la capital de Francia?\n",
      "  - Respuesta: La capital de Francia es Par√≠s....\n"
     ]
    }
   ],
   "source": [
    "# Configurar el modelo de lenguaje\n",
    "llm = ChatOpenAI(\n",
    "    model=CONFIG[\"llm_model\"],\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    temperature=0,\n",
    "    max_tokens=2000\n",
    ")\n",
    "\n",
    "print(f\"ü§ñ Modelo de lenguaje configurado: {CONFIG['llm_model']}\")\n",
    "print(f\"  - Temperatura: 0 (respuestas determin√≠sticas)\")\n",
    "print(f\"  - Tokens m√°ximos: 2000\")\n",
    "\n",
    "# Probar el modelo\n",
    "test_prompt = \"¬øCu√°l es la capital de Francia?\"\n",
    "try:\n",
    "    response = llm.invoke(test_prompt)\n",
    "    print(f\"\\nüß™ Prueba del LLM:\")\n",
    "    print(f\"  - Pregunta: {test_prompt}\")\n",
    "    print(f\"  - Respuesta: {response.content[:100]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error probando LLM: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "setup_qa_chain",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T06:29:56.857676Z",
     "start_time": "2025-09-17T06:29:56.854633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Cadena de QA configurada exitosamente\n",
      "  - Tipo de cadena: stuff\n",
      "  - Retorna documentos fuente: S√≠\n",
      "  - Retrieval: MMR optimizado\n",
      "  - Modo verbose: No\n"
     ]
    }
   ],
   "source": [
    "# Configurar la cadena de pregunta-respuesta\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",  # \"stuff\" significa incluir todos los documentos recuperados en el prompt\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"üîó Cadena de QA configurada exitosamente\")\n",
    "print(\"  - Tipo de cadena: stuff\")\n",
    "print(\"  - Retorna documentos fuente: S√≠\")\n",
    "print(\"  - Retrieval: MMR optimizado\")\n",
    "print(\"  - Modo verbose: No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "test_qa_system",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T06:29:56.874270Z",
     "start_time": "2025-09-17T06:29:56.870503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Preparadas 7 preguntas de prueba (incluyendo validaci√≥n cr√≠tica)\n",
      "  1. ¬øCu√°ntos d√≠as de vacaciones tienen los empleados nuevos?\n",
      "  2. ¬øCu√°l es la pol√≠tica de trabajo remoto de la empresa?\n",
      "  3. ¬øQu√© est√°ndares de c√≥digo se deben seguir para Python?\n",
      "  4. ¬øCu√°l es el proceso para hacer deploy a producci√≥n?\n",
      "  5. ¬øQu√© porcentaje m√≠nimo de cobertura de tests se requiere?\n",
      "  6. ¬øCu√°les son los horarios espec√≠ficos para trabajo remoto y qu√© aprobaci√≥n se necesita?\n",
      "  7. ¬øQu√© diferencia hay entre los d√≠as de vacaciones de empleados con 2 a√±os vs 5 a√±os de antig√ºedad?\n"
     ]
    }
   ],
   "source": [
    "# Funci√≥n para procesar consultas\n",
    "def query_rag_system(question: str, return_sources: bool = True):\n",
    "    \"\"\"Procesa una consulta y genera respuesta con el sistema RAG optimizado\"\"\"\n",
    "    print(f\"‚ùì Procesando consulta: {question}\")\n",
    "    \n",
    "    try:\n",
    "        result = qa_chain.invoke({\"query\": question})\n",
    "        \n",
    "        response = {\n",
    "            \"question\": question,\n",
    "            \"answer\": result[\"result\"],\n",
    "            \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        \n",
    "        if return_sources and \"source_documents\" in result:\n",
    "            sources = []\n",
    "            for i, doc in enumerate(result[\"source_documents\"]):\n",
    "                source_info = {\n",
    "                    \"document_id\": i + 1,\n",
    "                    \"source_file\": doc.metadata.get(\"source_file\", \"Unknown\"),\n",
    "                    \"chunk_id\": doc.metadata.get(\"chunk_id\", \"Unknown\"),\n",
    "                    \"content_preview\": doc.page_content[:200] + \"...\"\n",
    "                }\n",
    "                sources.append(source_info)\n",
    "                \n",
    "            response[\"sources\"] = sources\n",
    "            response[\"num_sources\"] = len(sources)\n",
    "            \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"answer\": f\"Error procesando consulta: {e}\",\n",
    "            \"error\": True,\n",
    "            \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "\n",
    "# Definir preguntas de prueba optimizadas (incluyendo cr√≠ticas)\n",
    "test_questions = [\n",
    "    \"¬øCu√°ntos d√≠as de vacaciones tienen los empleados nuevos?\",\n",
    "    \"¬øCu√°l es la pol√≠tica de trabajo remoto de la empresa?\", \n",
    "    \"¬øQu√© est√°ndares de c√≥digo se deben seguir para Python?\",\n",
    "    \"¬øCu√°l es el proceso para hacer deploy a producci√≥n?\",\n",
    "    \"¬øQu√© porcentaje m√≠nimo de cobertura de tests se requiere?\",\n",
    "    \"¬øCu√°les son los horarios espec√≠ficos para trabajo remoto y qu√© aprobaci√≥n se necesita?\",\n",
    "    \"¬øQu√© diferencia hay entre los d√≠as de vacaciones de empleados con 2 a√±os vs 5 a√±os de antig√ºedad?\"\n",
    "]\n",
    "\n",
    "print(f\"üìù Preparadas {len(test_questions)} preguntas de prueba (incluyendo validaci√≥n cr√≠tica)\")\n",
    "for i, q in enumerate(test_questions, 1):\n",
    "    print(f\"  {i}. {q}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "execute_queries",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T06:30:20.816633Z",
     "start_time": "2025-09-17T06:29:56.885412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Ejecutando consultas del sistema RAG optimizado\n",
      "============================================================\n",
      "\n",
      "--- Consulta 1/7 ---\n",
      "‚ùì Procesando consulta: ¬øCu√°ntos d√≠as de vacaciones tienen los empleados nuevos?\n",
      "‚úÖ Respuesta: Los empleados nuevos tienen 15 d√≠as de vacaciones al a√±o.\n",
      "\n",
      "üìö Fuentes utilizadas (MMR diversificado - 5):\n",
      "   - manual_politicas.txt (fragmento 31)\n",
      "   - manual_politicas.txt (fragmento 31)\n",
      "   - manual_politicas.txt (fragmento 31)\n",
      "   - manual_politicas.txt (fragmento 30)\n",
      "   - manual_politicas.txt (fragmento 30)\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Consulta 2/7 ---\n",
      "‚ùì Procesando consulta: ¬øCu√°l es la pol√≠tica de trabajo remoto de la empresa?\n",
      "‚úÖ Respuesta: La pol√≠tica de trabajo remoto de la empresa TechCorp establece lo siguiente:\n",
      "\n",
      "1. **Elegibilidad**: Los empleados pueden trabajar de forma remota si:\n",
      "   - Han completado al menos 6 meses en la empresa.\n",
      "   - Su supervisor directo aprueba la solicitud.\n",
      "   - Su rol permite trabajo remoto efectivo.\n",
      "\n",
      "2. **Horarios de Trabajo**:\n",
      "   - Horario flexible entre 7:00 AM y 7:00 PM.\n",
      "   - M√≠nimo 6 horas de solapamiento con el equipo.\n",
      "   - Disponibilidad para reuniones importantes.\n",
      "\n",
      "üìö Fuentes utilizadas (MMR diversificado - 5):\n",
      "   - manual_politicas.txt (fragmento 30)\n",
      "   - manual_politicas.txt (fragmento 30)\n",
      "   - manual_politicas.txt (fragmento 30)\n",
      "   - manual_politicas.txt (fragmento 22)\n",
      "   - manual_politicas.txt (fragmento 22)\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Consulta 3/7 ---\n",
      "‚ùì Procesando consulta: ¬øQu√© est√°ndares de c√≥digo se deben seguir para Python?\n",
      "‚úÖ Respuesta: Para Python, se debe seguir PEP 8. Adem√°s, todos los m√©todos p√∫blicos deben tener docstrings, y es obligatorio incluir un README.md en cada repositorio, as√≠ como comentarios en c√≥digo complejo.\n",
      "\n",
      "üìö Fuentes utilizadas (MMR diversificado - 5):\n",
      "   - guia_desarrollo.txt (fragmento 20)\n",
      "   - guia_desarrollo.txt (fragmento 20)\n",
      "   - guia_desarrollo.txt (fragmento 20)\n",
      "   - guia_desarrollo.txt (fragmento 15)\n",
      "   - manual_politicas.txt (fragmento 1)\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Consulta 4/7 ---\n",
      "‚ùì Procesando consulta: ¬øCu√°l es el proceso para hacer deploy a producci√≥n?\n",
      "‚úÖ Respuesta: El proceso para hacer deploy a producci√≥n es el siguiente:\n",
      "\n",
      "1. Realizar el deploy solo desde la rama main.\n",
      "2. Hacer un backup antes de cada deploy a producci√≥n.\n",
      "3. Tener un plan de rollback siempre disponible.\n",
      "\n",
      "üìö Fuentes utilizadas (MMR diversificado - 5):\n",
      "   - guia_desarrollo.txt (fragmento 22)\n",
      "   - guia_desarrollo.txt (fragmento 22)\n",
      "   - guia_desarrollo.txt (fragmento 22)\n",
      "   - guia_desarrollo.txt (fragmento 21)\n",
      "   - guia_desarrollo.txt (fragmento 16)\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Consulta 5/7 ---\n",
      "‚ùì Procesando consulta: ¬øQu√© porcentaje m√≠nimo de cobertura de tests se requiere?\n",
      "‚úÖ Respuesta: Se requiere un m√≠nimo del 80% de cobertura de c√≥digo.\n",
      "\n",
      "üìö Fuentes utilizadas (MMR diversificado - 5):\n",
      "   - guia_desarrollo.txt (fragmento 16)\n",
      "   - guia_desarrollo.txt (fragmento 21)\n",
      "   - guia_desarrollo.txt (fragmento 21)\n",
      "   - manual_politicas.txt (fragmento 23)\n",
      "   - guia_desarrollo.txt (fragmento 20)\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Consulta 6/7 ---\n",
      "‚ùì Procesando consulta: ¬øCu√°les son los horarios espec√≠ficos para trabajo remoto y qu√© aprobaci√≥n se necesita?\n",
      "‚úÖ Respuesta: Los horarios espec√≠ficos para trabajo remoto son flexibles entre 7:00 AM y 7:00 PM, con un m√≠nimo de 6 horas de solapamiento con el equipo y disponibilidad para reuniones importantes. Adem√°s, se requiere la aprobaci√≥n del supervisor directo para poder trabajar de forma remota.\n",
      "\n",
      "üìö Fuentes utilizadas (MMR diversificado - 5):\n",
      "   - manual_politicas.txt (fragmento 30)\n",
      "   - manual_politicas.txt (fragmento 30)\n",
      "   - manual_politicas.txt (fragmento 30)\n",
      "   - manual_politicas.txt (fragmento 0)\n",
      "   - manual_politicas.txt (fragmento 1)\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Consulta 7/7 ---\n",
      "‚ùì Procesando consulta: ¬øQu√© diferencia hay entre los d√≠as de vacaciones de empleados con 2 a√±os vs 5 a√±os de antig√ºedad?\n",
      "‚úÖ Respuesta: La diferencia en los d√≠as de vacaciones es de 5 d√≠as. Los empleados con 2 o m√°s a√±os de antig√ºedad tienen derecho a 20 d√≠as de vacaciones al a√±o, mientras que los empleados con 5 o m√°s a√±os de antig√ºedad tienen derecho a 25 d√≠as al a√±o.\n",
      "\n",
      "üìö Fuentes utilizadas (MMR diversificado - 5):\n",
      "   - manual_politicas.txt (fragmento 31)\n",
      "   - manual_politicas.txt (fragmento 31)\n",
      "   - manual_politicas.txt (fragmento 31)\n",
      "   - manual_politicas.txt (fragmento 30)\n",
      "   - manual_politicas.txt (fragmento 30)\n",
      "------------------------------------------------------------\n",
      "\n",
      "‚úÖ Completadas todas las consultas optimizadas!\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar todas las consultas de prueba\n",
    "print(\"üöÄ Ejecutando consultas del sistema RAG optimizado\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n--- Consulta {i}/{len(test_questions)} ---\")\n",
    "    \n",
    "    result = query_rag_system(question)\n",
    "    results.append(result)\n",
    "    \n",
    "    print(f\"‚úÖ Respuesta: {result['answer']}\")\n",
    "    \n",
    "    if 'sources' in result:\n",
    "        print(f\"\\nüìö Fuentes utilizadas (MMR diversificado - {result['num_sources']}):\")\n",
    "        for source in result['sources']:\n",
    "            print(f\"   - {source['source_file']} (fragmento {source['chunk_id']})\")\n",
    "    \n",
    "    if 'error' in result:\n",
    "        print(f\"‚ùå Error: {result['answer']}\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Pausa entre consultas para evitar rate limits\n",
    "    if i < len(test_questions):\n",
    "        time.sleep(2)\n",
    "\n",
    "print(f\"\\n‚úÖ Completadas todas las consultas optimizadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "save_results",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T06:30:20.855270Z",
     "start_time": "2025-09-17T06:30:20.850367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Resultados guardados en: rag_results.json\n",
      "\n",
      "üìä Estad√≠sticas finales optimizadas:\n",
      "  - Total de consultas: 7\n",
      "  - Consultas exitosas: 7\n",
      "  - Consultas fallidas: 0\n",
      "  - Tasa de √©xito: 100.0%\n",
      "\n",
      "üèóÔ∏è Informaci√≥n del sistema optimizado:\n",
      "  - Documentos originales: 5\n",
      "  - Fragmentos creados: 32 (chunks optimizados de 800 chars)\n",
      "  - Documentos en vectorstore: 233\n",
      "  - Modelo LLM: gpt-4o-mini\n",
      "  - Modelo embeddings: text-embedding-3-small\n",
      "  - Retrieval: MMR con k=5\n",
      "  - Base de datos: ./chroma_db\n",
      "  - Carga: Autom√°tica desde sample_docs/\n"
     ]
    }
   ],
   "source": [
    "# Guardar resultados en archivo JSON\n",
    "results_file = \"rag_results.json\"\n",
    "\n",
    "with open(results_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"üíæ Resultados guardados en: {results_file}\")\n",
    "\n",
    "# Mostrar estad√≠sticas finales\n",
    "successful_queries = len([r for r in results if 'error' not in r])\n",
    "failed_queries = len([r for r in results if 'error' in r])\n",
    "\n",
    "print(f\"\\nüìä Estad√≠sticas finales optimizadas:\")\n",
    "print(f\"  - Total de consultas: {len(results)}\")\n",
    "print(f\"  - Consultas exitosas: {successful_queries}\")\n",
    "print(f\"  - Consultas fallidas: {failed_queries}\")\n",
    "print(f\"  - Tasa de √©xito: {(successful_queries/len(results)*100):.1f}%\")\n",
    "\n",
    "# Mostrar informaci√≥n del sistema optimizado\n",
    "print(f\"\\nüèóÔ∏è Informaci√≥n del sistema optimizado:\")\n",
    "print(f\"  - Documentos originales: {len(documents)}\")\n",
    "print(f\"  - Fragmentos creados: {len(chunks)} (chunks optimizados de 800 chars)\")\n",
    "print(f\"  - Documentos en vectorstore: {vectorstore._collection.count()}\")\n",
    "print(f\"  - Modelo LLM: {CONFIG['llm_model']}\")\n",
    "print(f\"  - Modelo embeddings: {CONFIG['embedding_model']}\")\n",
    "print(f\"  - Retrieval: {CONFIG['search_type'].upper()} con k={CONFIG['retrieval_k']}\")\n",
    "print(f\"  - Base de datos: {CONFIG['persist_directory']}\")\n",
    "print(f\"  - Carga: Autom√°tica desde sample_docs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "interactive_query",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T06:30:23.118140Z",
     "start_time": "2025-09-17T06:30:20.867911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Secci√≥n interactiva - Haz tu propia consulta\n",
      "Puedes modificar la variable 'custom_question' y ejecutar esta celda\n",
      "Aprovecha las optimizaciones: MMR retrieval, chunks de 800 chars, carga autom√°tica\n",
      "\n",
      "Pregunta personalizada (validaci√≥n cr√≠tica): ¬øQu√© requisitos espec√≠ficos hay para trabajar de forma remota y cu√°les son exactamente los horarios permitidos?\n",
      "‚ùì Procesando consulta: ¬øQu√© requisitos espec√≠ficos hay para trabajar de forma remota y cu√°les son exactamente los horarios permitidos?\n",
      "\n",
      "‚úÖ Respuesta personalizada:\n",
      "Para trabajar de forma remota en TechCorp, los requisitos espec√≠ficos son:\n",
      "\n",
      "1. Haber completado al menos 6 meses en la empresa.\n",
      "2. Tener la aprobaci√≥n de su supervisor directo.\n",
      "3. Su rol debe permitir trabajo remoto efectivo.\n",
      "\n",
      "En cuanto a los horarios permitidos, son los siguientes:\n",
      "\n",
      "- Horario flexible entre 7:00 AM y 7:00 PM.\n",
      "- M√≠nimo 6 horas de solapamiento con el equipo.\n",
      "- Disponibilidad para reuniones importantes.\n",
      "\n",
      "üìö Fuentes consultadas (MMR diversificado):\n",
      "   - manual_politicas.txt\n",
      "     Preview: Manual de Pol√≠ticas de la Empresa TechCorp\n",
      "\n",
      "1. POL√çTICAS DE TRABAJO REMOTO\n",
      "\n",
      "1.1 Elegibilidad\n",
      "Los empleados pueden trabajar de forma remota si:\n",
      "- Han c...\n",
      "   - manual_politicas.txt\n",
      "     Preview: Manual de Pol√≠ticas de la Empresa TechCorp\n",
      "\n",
      "1. POL√çTICAS DE TRABAJO REMOTO\n",
      "\n",
      "1.1 Elegibilidad\n",
      "Los empleados pueden trabajar de forma remota si:\n",
      "- Han c...\n",
      "   - manual_politicas.txt\n",
      "     Preview: Manual de Pol√≠ticas de la Empresa TechCorp\n",
      "    \n",
      "    1. POL√çTICAS DE TRABAJO REMOTO\n",
      "    \n",
      "    1.1 Elegibilidad\n",
      "    Los empleados pueden trabajar de form...\n",
      "   - manual_politicas.txt\n",
      "     Preview: Manual de Pol√≠ticas de la Empresa TechCorp\n",
      "    \n",
      "    1. POL√çTICAS DE TRABAJO REMOTO\n",
      "    \n",
      "    1.1 Elegibilidad\n",
      "    Los empleados pueden trabajar de form...\n",
      "   - manual_politicas.txt\n",
      "     Preview: - Empleados con 2+ a√±os: 20 d√≠as al a√±o\n",
      "    - Empleados con 5+ a√±os: 25 d√≠as al a√±o\n",
      "    \n",
      "    2.2 Solicitud de Vacaciones\n",
      "    - Solicitar con al menos ...\n"
     ]
    }
   ],
   "source": [
    "# Secci√≥n interactiva para consultas personalizadas\n",
    "print(\"üéØ Secci√≥n interactiva - Haz tu propia consulta\")\n",
    "print(\"Puedes modificar la variable 'custom_question' y ejecutar esta celda\")\n",
    "print(\"Aprovecha las optimizaciones: MMR retrieval, chunks de 800 chars, carga autom√°tica\")\n",
    "\n",
    "# Modifica esta pregunta para probar el sistema optimizado\n",
    "custom_question = \"¬øQu√© requisitos espec√≠ficos hay para trabajar de forma remota y cu√°les son exactamente los horarios permitidos?\"\n",
    "\n",
    "print(f\"\\nPregunta personalizada (validaci√≥n cr√≠tica): {custom_question}\")\n",
    "custom_result = query_rag_system(custom_question)\n",
    "\n",
    "print(f\"\\n‚úÖ Respuesta personalizada:\")\n",
    "print(custom_result['answer'])\n",
    "\n",
    "if 'sources' in custom_result:\n",
    "    print(f\"\\nüìö Fuentes consultadas (MMR diversificado):\")\n",
    "    for source in custom_result['sources']:\n",
    "        print(f\"   - {source['source_file']}\")\n",
    "        print(f\"     Preview: {source['content_preview'][:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion_header",
   "metadata": {},
   "source": [
    "## üéØ Conclusiones y Pr√≥ximos Pasos\n",
    "\n",
    "### ‚úÖ Objetivos Cumplidos con Optimizaciones\n",
    "\n",
    "1. **Carga autom√°tica**: ‚úÖ Detecci√≥n autom√°tica desde sample_docs/\n",
    "2. **Extracci√≥n de archivos**: ‚úÖ Implementado soporte para PDF y TXT\n",
    "3. **Chunking optimizado**: ‚úì Fragmentos de 1200 chars con overlap 200\\n4. **Embeddings**: ‚úÖ Vectorizaci√≥n con OpenAI text-embedding-3-small\n",
    "5. **Base de datos vectorial**: ‚úÖ Almacenamiento persistente con ChromaDB\n",
    "6. **Recuperaci√≥n MMR**: ‚úÖ B√∫squeda con Maximal Marginal Relevance\n",
    "7. **Generaci√≥n**: ‚úÖ Respuestas contextualizadas con GPT-4o-mini\n",
    "8. **Validaci√≥n cr√≠tica**: ‚úÖ Preguntas espec√≠ficas para entidades y relaciones\n",
    "\n",
    "### üìä Rendimiento del Sistema Optimizado\n",
    "\n",
    "- **Precisi√≥n mejorada**: Respuestas con mayor continuidad contextual\n",
    "- **Diversidad sem√°ntica**: Retrieval MMR genera respuestas m√°s completas\n",
    "- **Automatizaci√≥n**: Carga autom√°tica de cualquier n√∫mero de documentos\n",
    "- **Validaci√≥n robusta**: Preguntas cr√≠ticas verifican entidades espec√≠ficas\n",
    "- **Escalabilidad**: Arquitectura preparada para m√°s documentos\n",
    "\n",
    "### üöÄ Mejoras Implementadas vs Versi√≥n Anterior\n",
    "\n",
    "1. **Chunking optimizado**: 1200 chars para mejor contexto\\n2. **Retrieval MMR**: Mayor diversidad vs similaridad simple\n",
    "3. **Carga autom√°tica**: No m√°s rutas hardcodeadas\n",
    "4. **Validaci√≥n cr√≠tica**: Preguntas espec√≠ficas para verificar precisi√≥n\n",
    "5. **Configuraci√≥n flexible**: Par√°metros centralizados y documentados\n",
    "\n",
    "### üéì Aprendizajes Clave Optimizados\n",
    "\n",
    "- **RAG vs LLM puro**: Mayor precisi√≥n y fundamentaci√≥n en datos reales\n",
    "- **Importancia del chunking optimizado**: Balance entre contexto y especificidad mejorado\n",
    "- **MMR vs Similarity**: Diversidad sem√°ntica cr√≠tica para respuestas completas\n",
    "- **Carga autom√°tica**: Escalabilidad sin intervenci√≥n manual\n",
    "- **Validaci√≥n cr√≠tica**: Esencial para verificar precisi√≥n en datos espec√≠ficos\n",
    "- **Persistencia optimizada**: Ventajas de configuraciones flexibles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
