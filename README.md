# Sistema RAG (Retrieval-Augmented Generation)

## ğŸ¯ DescripciÃ³n del Proyecto

Este proyecto implementa un sistema completo de **RAG (Retrieval-Augmented Generation)** que permite a los usuarios consultar documentos internos de manera inteligente. El sistema combina la recuperaciÃ³n de informaciÃ³n especÃ­fica con la generaciÃ³n de respuestas contextualizadas usando modelos de IA generativa.

### âœ¨ CaracterÃ­sticas Principales

- **Carga automÃ¡tica**: DetecciÃ³n y procesamiento automÃ¡tico de archivos desde sample_docs/
- **ExtracciÃ³n de documentos**: Soporte para archivos PDF y TXT
- Chunking optimizado: DivisiÃ³n en fragmentos de 1200 caracteres con overlap de 200
- **Embeddings vectoriales**: Usando OpenAI text-embedding-3-small
- **Base de datos vectorial**: Almacenamiento persistente con ChromaDB
- **RecuperaciÃ³n MMR**: BÃºsqueda con Maximal Marginal Relevance para mayor diversidad
- **GeneraciÃ³n contextualizada**: Respuestas inteligentes con GPT-4o-mini
- **ValidaciÃ³n crÃ­tica**: Preguntas especÃ­ficas para validar entidades y relaciones
- **CI/CD automatizado**: ValidaciÃ³n continua con GitHub Actions

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   sample_docs/  â”‚â”€â”€â”€â”€â”‚   Carga          â”‚â”€â”€â”€â”€â”‚   Chunking      â”‚
â”‚   (PDF/TXT)     â”‚    â”‚   AutomÃ¡tica     â”‚    â”‚   (1200/200)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Respuesta     â”‚â—„â”€â”€â”€â”‚   LLM GPT-4o     â”‚â—„â”€â”€â”€â”‚   ChromaDB      â”‚
â”‚   + Fuentes     â”‚    â”‚   + MMR Context  â”‚    â”‚   (Vectores)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â–²
                                 â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   Consulta       â”‚
                         â”‚   del Usuario    â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos

- Python 3.8+
- Cuenta de OpenAI con API key
- Git (para CI/CD)

### Paso 1: Clonar el repositorio

```bash
git clone <tu-repositorio>
cd sistema-rag
```

### Paso 2: Instalar dependencias

```bash
pip install -r requirements.txt
```

### Paso 3: Configurar variables de entorno

```bash
# Copiar template
cp .env.template .env

# Editar .env y agregar tu API key
OPENAI_API_KEY=sk-tu-api-key-aqui
```

### Paso 4: Ejecutar el sistema

```bash
python RETO_RAG.py
```

## ğŸ“š Uso del Sistema

### EjecuciÃ³n BÃ¡sica

El sistema incluye documentos de ejemplo y se ejecuta automÃ¡ticamente:

```python
from RETO_RAG import RAGSystem, create_sample_documents

# Inicializar sistema
rag_system = RAGSystem()

# Cargar documentos
documents = rag_system.doc_processor.load_documents(file_paths)

# Procesar y construir base de datos
chunks = rag_system.text_chunker.split_documents(documents)
rag_system.build_vectorstore(chunks)
rag_system.setup_retriever()
rag_system.setup_qa_chain()

# Hacer consultas
result = rag_system.query("Â¿CuÃ¡l es la polÃ­tica de vacaciones?")
print(result["answer"])
```

### Consultas de Ejemplo

El sistema incluye estas consultas de prueba optimizadas:

**Preguntas directas (respondibles con los documentos):**
1. "Â¿CuÃ¡ntos dÃ­as de vacaciones tienen los empleados nuevos?"
2. "Â¿CuÃ¡l es la polÃ­tica de trabajo remoto de la empresa?"
3. "Â¿QuÃ© estÃ¡ndares de cÃ³digo se deben seguir para Python?"
4. "Â¿CuÃ¡l es el proceso para hacer deploy a producciÃ³n?"
5. "Â¿QuÃ© porcentaje mÃ­nimo de cobertura de tests se requiere?"

**Preguntas capciosas (para validar comportamiento ante datos no disponibles):**
6. "Â¿CuÃ¡l fue el producto mÃ¡s vendido de TechCorp durante el segundo trimestre de 2024?"
7. "Â¿QuÃ© cliente del sector salud adquiriÃ³ VisionBox AI y en quÃ© aÃ±o?"
8. "Â¿CuÃ¡l fue el ahorro mensual tras la migraciÃ³n a la nube durante 2025?"

Estas preguntas capciosas validan que el sistema no invente informaciÃ³n no disponible en los documentos.

## ğŸ”§ ConfiguraciÃ³n Avanzada

### ParÃ¡metros del Sistema

```python
# ConfiguraciÃ³n de chunking
text_chunker = TextChunker(
    chunk_size=1200,      # TamaÃ±o de fragmento optimizado
    chunk_overlap=200     # Solapamiento para continuidad
)

# ConfiguraciÃ³n de recuperaciÃ³n
rag_system.setup_retriever(
    k=7,                  # NÃºmero de documentos a recuperar
    search_type="mmr",    # MMR para mayor diversidad
    fetch_k=20,           # Candidatos para MMR
    lambda_mult=0.5       # Balance diversidad vs relevancia
)

# Carga automÃ¡tica de documentos
documents = load_documents_from_directory("sample_docs/")
```

### Modelos y ConfiguraciÃ³n

- **LLM**: GPT-4o-mini (OpenAI) con temperatura 0
- **Embeddings**: text-embedding-3-small (OpenAI)
- **Vector Store**: ChromaDB con persistencia local
- **Chunking**: 1200 caracteres con overlap 200
- **Retrieval**: MMR (Maximal Marginal Relevance) con k=7
- **Carga**: AutomÃ¡tica desde directorio sample_docs/

## ğŸ§ª Testing y CI/CD

### GitHub Actions

El proyecto incluye un workflow completo de CI/CD:

```yaml
# .github/workflows/rag-ci.yml
- InstalaciÃ³n de dependencias
- EjecuciÃ³n del sistema RAG
- ValidaciÃ³n de resultados
- AnÃ¡lisis de seguridad
- Tests de rendimiento
```

### Configurar Secrets en GitHub

1. Ve a Settings â†’ Secrets and variables â†’ Actions
2. Agrega: `OPENAI_API_KEY` con tu API key

### Ejecutar Tests Localmente

```bash
# Test bÃ¡sico
python RETO_RAG.py

# Verificar resultados
cat rag_results.json
```

## ğŸ“Š Resultados y MÃ©tricas

### Archivos Generados

- `rag_results.json`: Resultados de las consultas
- `chroma_db/`: Base de datos vectorial persistente
- `sample_docs/`: Documentos de ejemplo

### MÃ©tricas del Sistema

- **Documentos procesados**: Carga automÃ¡tica desde sample_docs/
- **Fragmentos creados**: ~25-35 chunks optimizados (1200 chars)
- **Tiempo de respuesta**: < 3 segundos por consulta
- **PrecisiÃ³n**: Respuestas basadas en documentos fuente con MMR
- **Diversidad**: Mayor cobertura semÃ¡ntica con retrieval MMR
- **ValidaciÃ³n**: 7 consultas incluyendo preguntas crÃ­ticas

## ğŸ”’ Seguridad y Mejores PrÃ¡cticas

### Seguridad

- âœ… API keys en variables de entorno
- âœ… No hardcodear credenciales
- âœ… ValidaciÃ³n de entradas
- âœ… Scanning automÃ¡tico de seguridad

### Mejores PrÃ¡cticas

- **Rate limiting**: Pausas entre llamadas a API
- **Error handling**: Manejo robusto de errores
- **Logging**: InformaciÃ³n detallada de ejecuciÃ³n
- **Modularidad**: CÃ³digo organizado en clases
- **Testing**: ValidaciÃ³n automatizada

## ğŸš§ Roadmap y Mejoras Futuras

### PrÃ³ximas Funcionalidades

- [ ] Soporte para mÃ¡s formatos (DOCX, CSV, Excel)
- [ ] Interface web con Streamlit
- [ ] BÃºsqueda hÃ­brida (MMR + keyword)
- [ ] MÃ©tricas de calidad automatizadas
- [ ] IntegraciÃ³n con modelos locales (Ollama)
- [ ] Filtros avanzados por metadata

### Optimizaciones Implementadas

- [x] Chunking optimizado (1200/200) para mejor contexto
- [x] Carga automÃ¡tica de documentos desde directorio
- [x] BÃºsqueda MMR para mayor diversidad semÃ¡ntica
- [x] ValidaciÃ³n con preguntas crÃ­ticas
- [x] Cache de embeddings para desarrollo
- [x] Respuestas con mayor cobertura contextual

## ğŸ“ Soporte y ContribuciÃ³n

### Problemas Comunes

**Error: "No module named 'chromadb'"**
```bash
pip install --upgrade chromadb
```

**Error: "Invalid API key"**
- Verifica que tu API key sea vÃ¡lida
- Revisa el archivo `.env`

**Error: "Rate limit exceeded"**
- El sistema incluye rate limiting automÃ¡tico
- Espera unos minutos y vuelve a intentar

### Contribuir

1. Fork del repositorio
2. Crear feature branch
3. Hacer commits descriptivos
4. Ejecutar tests
5. Crear Pull Request

## ğŸ“„ Licencia

Este proyecto es parte del Certificado en Desarrollo de Software con IA Generativa.

## ğŸ“ Contexto AcadÃ©mico

### Objetivos de Aprendizaje Cumplidos

- âœ… ImplementaciÃ³n de sistema RAG funcional con optimizaciones
- âœ… Uso de embeddings vectoriales con retrieval MMR
- âœ… IntegraciÃ³n con modelos de IA generativa optimizada
- âœ… ConfiguraciÃ³n de CI/CD automatizado
- âœ… AplicaciÃ³n de prompt engineering avanzado
- âœ… Mejores prÃ¡cticas de desarrollo con validaciÃ³n crÃ­tica
- âœ… Carga automÃ¡tica y chunking optimizado

### Respuestas al Cuestionario

1. **Principal ventaja de RAG**: b) Respuestas mÃ¡s precisas y fundamentadas en datos
2. **Componente de bÃºsqueda**: b) El indexador vectorial
3. **LimitaciÃ³n de IA generativa**: b) Puede inventar informaciÃ³n o cometer errores de lÃ³gica
4. **QuÃ© es Ollama**: c) Una plataforma para ejecutar modelos generativos localmente
5. **Importancia de revisar cÃ³digo**: b) Para asegurarse de que cumple con los estÃ¡ndares y es seguro

### ReflexiÃ³n sobre RAG

Los sistemas RAG representan un paradigma transformador para los desarrolladores, permitiendo:

- **Acceso contextualizado**: InformaciÃ³n especÃ­fica sin necesidad de buscar manualmente
- **Conocimiento actualizado**: Respuestas basadas en documentaciÃ³n actual
- **DemocratizaciÃ³n del conocimiento**: Acceso fÃ¡cil para todos los miembros del equipo
- **Eficiencia mejorada**: ReducciÃ³n del tiempo de bÃºsqueda de informaciÃ³n

**Ejemplo prÃ¡ctico**: Un desarrollador puede preguntar "Â¿CÃ³mo configurar el deploy para el microservicio de pagos?" y obtener una respuesta especÃ­fica basada en la documentaciÃ³n interna, en lugar de revisar mÃºltiples archivos manualmente.

---

**Desarrollado por**: [Tu Nombre]  
**Fecha**: Septiembre 2025  
**VersiÃ³n**: 1.0.0